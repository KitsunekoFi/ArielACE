{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quadragonsaurus/ArielACE/blob/main/NekoFi_SuperLazy_Cafe_TI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "FtRTSsVA5R8N",
        "outputId": "bc5e3e79-843a-43b1-8bc4-8bd047668fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 16 05:29:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    28W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxddEaEIvGuw",
        "outputId": "1829676a-2b4e-4a70-b39c-2fc6c22f9e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://huggingface.co/Schisim/Clarity/resolve/main/Clarity_1.9.ckpt\n",
            "To: /content/sd_text_inversion/Clarity_1.9.ckpt\n",
            " 44% 1.89G/4.27G [00:56<00:54, 43.5MB/s]"
          ]
        }
      ],
      "source": [
        "#@title Installing the required\n",
        "#@markdown Please don't check this first, I haven't optimized it yet.\n",
        "use_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "if use_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  %cd /content/drive/MyDrive\n",
        "else:\n",
        "  %cd /content\n",
        "\n",
        "!pip install -q -U gdown\n",
        "url = \"https://huggingface.co/Schisim/Clarity/resolve/main/Clarity_1.9.ckpt\" #@param {type:\"string\"}\n",
        "\n",
        "if use_drive:\n",
        "  !gdown {url} -O /content/drive/MyDrive/sd_text_inversion/\n",
        "else:\n",
        "  !gdown {url} -O /content/sd_text_inversion/\n",
        " \n",
        "if use_drive:\n",
        "  %cd /content/drive/MyDrive\n",
        "  !mkdir sd_text_inversion\n",
        "  %cd sd_text_inversion\n",
        "  !mkdir modelsbackup\n",
        "  !mkdir stable-textual-inversion-cafe\n",
        "  !mkdir logs\n",
        "  !mkdir output\n",
        "  !mkdir train_data\n",
        "  !rm -rf stable-textual-inversion-cafe\n",
        "  %cd /content/drive/MyDrive/sd_text_inversion\n",
        "  !git clone https://github.com/Raearn/stable-textual-inversion-cafe.git\n",
        "  %cd stable-textual-inversion-cafe\n",
        "else:\n",
        "  %cd /content\n",
        "  !mkdir sd_text_inversion\n",
        "  %cd sd_text_inversion\n",
        "  !mkdir modelsbackup\n",
        "  !mkdir stable-textual-inversion-cafe\n",
        "  !mkdir logs\n",
        "  !mkdir output\n",
        "  !rm -rf stable-textual-inversion-cafe\n",
        "  %cd /content/sd_text_inversion\n",
        "  !git clone https://github.com/Raearn/stable-textual-inversion-cafe.git\n",
        "  %cd stable-textual-inversion-cafe\n",
        "\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "print(\"Done.\")\n",
        "\n",
        "if use_drive:\n",
        "  %cd /content/drive/MyDrive/sd_text_inversion/stable-textual-inversion-cafe\n",
        "else:\n",
        "  %cd /content/sd_text_inversion/stable-textual-inversion-cafe\n",
        "\n",
        "!pip install omegaconf einops pytorch-lightning==1.6.5 test-tube transformers kornia -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install setuptools==59.5.0\n",
        "!pip install pillow==9.0.1\n",
        "!pip install torchmetrics==0.6.0\n",
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install torchtext==0.13.1\n",
        "!pip install -e .\n",
        "\n",
        "print(\"Done. run the cell under this to start training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start TI Training\n",
        "#@markdown Dont't use any space in project_name, you can use underscore (_) instead.<p>\n",
        "auto = \"auto\"\n",
        "project_name = \"tsumuri\" #@param {type:\"string\"}\n",
        "#@markdown If you change the `initializer_words`, make sure you keep the syntax correct.                       \n",
        "initializer_words = [\"girl\",\"face\",\"hair\",\"eyes\",\"clothes\"] #@param {type:\"raw\"}\n",
        "#@markdown If you are not sure how much vectors you need, you can set `num_vectors_per_token` to `auto` instead of a number. <p>\n",
        "num_vectors_per_token = auto #@param {type:\"raw\"}                                               \n",
        "ti_type = \"character\" #@param [\"character\", \"artstyle\"]\n",
        "model = \"/content/sd_text_inversion/nai-wd.ckpt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown # Dataset part\n",
        "#@markdown First please choose if you want to use a huggingface/drive link or a path <br>\n",
        "#@markdown Then specify the `url` or the `dataset_path` <br>\n",
        "\n",
        "path_type = \"path\" #@param [\"path\", \"url\"]\n",
        "\n",
        "url = \"\" #@param {type:\"string\"}\n",
        "dataset_path = \"/content/train_data\" #@param {type:\"string\"}\n",
        "#@markdown ## *After setting each values, don't forget to click the run button.*\n",
        "#@title Downloading dataset and creating training configuration yaml\n",
        "#@markdown After running this cell, you can still check your configuration if you want to modify anything.\n",
        "#@markdown It is located in the `/content/sd_text_inversion/stable-textual-inversion-cafe/configs/stable-diffusion` folder, named as `<project_name>.yaml`\n",
        "\n",
        "import os\n",
        "\n",
        "# downloading dataset\n",
        "if (path_type == \"url\"):\n",
        "    if (url.startswith(\"https://drive.google.com\")):\n",
        "        !gdown {url} -O /content/{project_name}\n",
        "    else:\n",
        "        !gdown {url} -O /content/{project_name}.zip\n",
        "    !unzip /content/{project_name}.zip -d /content/sd_text_inversion/Imagesfortraining/{project_name}\n",
        "    num_images = len(os.listdir('/content/sd_text_inversion/Imagesfortraining/' + project_name))\n",
        "else:\n",
        "    num_images = len(os.listdir(dataset_path))\n",
        "\n",
        "# loading the base config\n",
        "import yaml\n",
        "with open(\"/content/sd_text_inversion/stable-textual-inversion-cafe/configs/stable-diffusion/\" + ti_type + \".yaml\", \"r\") as f:\n",
        "    base_config = yaml.safe_load(f)\n",
        "\n",
        "# calulate the number of vectors per token from the number of images\n",
        "if num_vectors_per_token == \"auto\":\n",
        "    num_vectors_per_token = round(num_images / 8.5)\n",
        "    if num_vectors_per_token < 8:\n",
        "        num_vectors_per_token = 8\n",
        "    if num_vectors_per_token > 18:\n",
        "        num_vectors_per_token = 18\n",
        "\n",
        "# calculating max steps\n",
        "if num_images <= 110:\n",
        "    max_steps = 11000\n",
        "else:\n",
        "    max_steps = 16000\n",
        "import math\n",
        "repeats = math.ceil(max_steps / num_images)\n",
        "\n",
        "# setting the parameters\n",
        "base_config[\"model\"][\"params\"][\"personalization_config\"][\"params\"][\"initializer_words\"] = initializer_words\n",
        "base_config[\"model\"][\"params\"][\"personalization_config\"][\"params\"][\"num_vectors_per_token\"] = num_vectors_per_token\n",
        "base_config[\"data\"][\"params\"][\"train\"][\"params\"][\"repeats\"] = repeats\n",
        "base_config[\"lightning\"][\"trainer\"][\"max_steps\"] = max_steps\n",
        "base_config[\"lightning\"][\"modelcheckpoint\"][\"params\"][\"every_n_train_steps\"] = 500\n",
        "base_config[\"lightning\"][\"callbacks\"][\"image_logger\"][\"params\"][\"batch_frequency\"] = 2000\n",
        "base_config[\"model\"][\"params\"][\"log_every_t\"] = 500\n",
        "\n",
        "# saving the config\n",
        "with open(\"/content/sd_text_inversion/stable-textual-inversion-cafe/configs/stable-diffusion/\" + project_name + \".yaml\", \"w\") as f:\n",
        "    yaml.dump(base_config, f)\n",
        "#@title Training\n",
        "#@markdown This block will train the TI, and when it's done, it will zip the checkpoints automatically. It will be available on your Google Drive, in `/content/sd_text_inversion/output` folder as `<project_name>.zip`\n",
        "if (ti_type == \"character\"):\n",
        "    initializer_word = \"character\"\n",
        "elif (ti_type == \"artstyle\"):\n",
        "    initializer_word = \"illustration\"\n",
        "\n",
        "if (path_type == \"url\"):\n",
        "  dataset = \"/content/sd_text_inversion/Imagesfortraining/\" + project_name\n",
        "else:\n",
        "  dataset = dataset_path\n",
        "config = \"/content/sd_text_inversion/stable-textual-inversion-cafe/configs/stable-diffusion/\" + project_name + \".yaml\"\n",
        "logs_folder = \"/content/sd_text_inversion/logs\"\n",
        "!mkdir /content/sd_text_inversion/logs\n",
        "!mkdir /content/sd_text_inversion/output\n",
        "\n",
        "%cd /content/sd_text_inversion/stable-textual-inversion-cafe\n",
        "!python \"main.py\" --base {config} -t --no-test --actual_resume {model}  -n {project_name} --gpus 1 --data_root {dataset} --init_word {initializer_word} --logdir {logs_folder}\n",
        "\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "dataset_name = dataset_path.split(\"/\")[-1]\n",
        "folders = os.listdir(logs_folder)\n",
        "folders = [folder for folder in folders if folder.startswith(dataset_name)]\n",
        "creation_times = [os.path.getctime(os.path.join(logs_folder, folder)) for folder in folders]\n",
        "ordered_folders = [folder for _, folder in sorted(zip(creation_times, folders))]\n",
        "newest_folder = ordered_folders[-1]\n",
        "\n",
        "%cd {logs_folder}/{newest_folder}\n",
        "!zip /content/sd_text_inversion/output/{project_name}.zip checkpoints/*\n",
        "print(\"Done! The checkpoints is saved in the output folder.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JJ_nxzI0xyE2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}